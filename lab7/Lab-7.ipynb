{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names \n",
    "Spencer Bernardo-Cheng\n",
    "Max Goldstein\n",
    "Robbie Keehan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   newy\n",
      "90    [-0.05970002000000022, -0.007700040000000002, ...\n",
      "91    [-0.007700040000000002, -0.018599999999999853,...\n",
      "92    [-0.018599999999999853, 0.018199920000000418, ...\n",
      "93    [0.018199920000000418, -0.002399910000000318, ...\n",
      "94    [-0.002399910000000318, 0.03550002999999975, -...\n",
      "...                                                 ...\n",
      "1873  [0.06349976000000197, -0.2489001499999995, 0.0...\n",
      "1874  [-0.2489001499999995, 0.014899910000001454, -0...\n",
      "1875  [0.014899910000001454, -0.1510998600000039, 0....\n",
      "1876  [-0.1510998600000039, 0.13040039000000206, 0.0...\n",
      "1877  [0.13040039000000206, 0.0026000999999996567, -...\n",
      "\n",
      "[1788 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "datafb = pd.read_csv(\"./FB.csv\")\n",
    "datagoogle = pd.read_csv(\"./GOOGL.csv\")\n",
    "datamsft = pd.read_csv(\"./MSFT.csv\")\n",
    "dataam = pd.read_csv(\"./AMZN (1).csv\")\n",
    "datanflx = pd.read_csv(\"./NFLX.csv\")\n",
    "\n",
    "del datafb['Date']\n",
    "del datagoogle['Date']\n",
    "del datamsft['Date']\n",
    "del datanflx['Date']\n",
    "\n",
    "\n",
    "data = pd.concat([datafb, datagoogle, datamsft,datanflx, dataam ], axis=1, sort=False)\n",
    "data = data[90:]\n",
    "del data['Change']\n",
    "del data['Gain']\n",
    "del data['Loss']\n",
    "del data['Average Gain']\n",
    "del data['Average Loss']\n",
    "del data['RS']\n",
    "del data['DM+1']\n",
    "del data['DM-1']\n",
    "del data['TR-14']\n",
    "del data['DM+1-14']\n",
    "del data['DM-1+14']\n",
    "del data['dl+1-14']\n",
    "del data['dl-1-14']\n",
    "del data['dl14diff']\n",
    "del data['dl14sum']\n",
    "del data['DX']\n",
    "del data['TR']\n",
    "del data['Date']\n",
    "\n",
    "predictedDays = 14\n",
    "up = .03\n",
    "down =-.03\n",
    "## Time difference the data\n",
    "colheaders = data.columns[0:-3]\n",
    "\n",
    "for header in colheaders: \n",
    "    for i in range(1, len(data)):\n",
    "        data[header].at[90+i-1]= ((data[header].iloc[i]) - (data[header].iloc[i - 1]))/100\n",
    "\n",
    "ydata = data['Close-amzn']\n",
    "# ydata = ydata.apply(lambda x:2 if x>=up else (1 if (x< up and x > down) else 0))\n",
    "ydata = pd.DataFrame(ydata)\n",
    "ydata['newy'] = \"\"\n",
    "# created target data in format to match output of multiple timesteps of 14 days ahead\n",
    "# [0,1,2,3,4,5,6,7]\n",
    "# [1,2,3,4,5,6,7,8]\n",
    "for index, row in ydata.iterrows():\n",
    "    temp = np.array(ydata['Close-amzn'][index-90:index-90+predictedDays].values)\n",
    "    ydata['newy'].at[index] = temp\n",
    "    \n",
    "# removed last 14 because their targets are not able to created\n",
    "ydata = ydata[0:-(predictedDays-1)]\n",
    "data = data[0:-(predictedDays-1)]\n",
    "del ydata['Close-amzn']\n",
    "\n",
    "\n",
    "        \n",
    "data = data[0:-1]\n",
    "ydata = ydata[0:-1]\n",
    "# data = data.T\n",
    "print(ydata)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Hot Encoding The Target Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 newy\n",
      "90  [-0.05970002000000022, -0.007700040000000002, ...\n",
      "91  [-0.007700040000000002, -0.018599999999999853,...\n",
      "92  [-0.018599999999999853, 0.018199920000000418, ...\n",
      "93  [0.018199920000000418, -0.002399910000000318, ...\n",
      "94  [-0.002399910000000318, 0.03550002999999975, -...\n",
      "                                                   newy\n",
      "90    [-0.05970002000000022, -0.007700040000000002, ...\n",
      "91    [-0.007700040000000002, -0.018599999999999853,...\n",
      "92    [-0.018599999999999853, 0.018199920000000418, ...\n",
      "93    [0.018199920000000418, -0.002399910000000318, ...\n",
      "94    [-0.002399910000000318, 0.03550002999999975, -...\n",
      "...                                                 ...\n",
      "1873  [0.06349976000000197, -0.2489001499999995, 0.0...\n",
      "1874  [-0.2489001499999995, 0.014899910000001454, -0...\n",
      "1875  [0.014899910000001454, -0.1510998600000039, 0....\n",
      "1876  [-0.1510998600000039, 0.13040039000000206, 0.0...\n",
      "1877  [0.13040039000000206, 0.0026000999999996567, -...\n",
      "\n",
      "[1788 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "print(ydata.head())\n",
    "# ydata['newy'] = ydata['newy'].apply(lambda x: to_categorical(x,3))\n",
    "print(ydata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Min-Max Scaling the Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6704866  0.63964878 0.66867271 ... 0.31321402 0.35811382 0.15022488]\n",
      " [0.67729607 0.65028702 0.68004011 ... 0.34297397 0.26414926 0.12331708]\n",
      " [0.67596742 0.64724754 0.67519221 ... 0.42513468 0.25300192 0.10448737]\n",
      " ...\n",
      " [0.64872934 0.62174942 0.65580059 ... 0.38193301 0.3029723  0.1344608 ]\n",
      " [0.7002159  0.67139486 0.709629   ... 0.44102474 0.31038595 0.1153046 ]\n",
      " [0.68310912 0.70618038 0.67184883 ... 0.40337188 0.25243424 0.13533161]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(data.iloc[:,:].values)\n",
    "print(x_scaled)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilizing Time Series Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00519989 -0.05550018 -0.0051001  ... -0.02950012  0.02890015\n",
      "   0.00970001]\n",
      " [-0.05550018 -0.0051001   0.03890015 ...  0.02890015  0.00970001\n",
      "  -0.09360016]\n",
      " [-0.0051001   0.03890015  0.01019989 ...  0.00970001 -0.09360016\n",
      "  -0.03919983]\n",
      " ...\n",
      " [ 0.01489991 -0.15109986  0.13040039 ... -0.19200073 -0.11640015\n",
      "  -0.0927002 ]\n",
      " [-0.15109986  0.13040039  0.0026001  ... -0.11640015 -0.0927002\n",
      "  -0.20209961]\n",
      " [ 0.13040039  0.0026001  -0.0726001  ... -0.0927002  -0.20209961\n",
      "   0.11119996]]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from numpy import hstack\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Lambda\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "n_input = 2\n",
    "series = np.array(x_scaled)\n",
    "target = np.array(ydata)\n",
    "generator = TimeseriesGenerator(series, target, length=90, batch_size=1)\n",
    "xtime = []\n",
    "ytarget =[]\n",
    "for i in range(len(generator)):\n",
    "    x, y = generator[i]\n",
    "    xtime.append(x[0])\n",
    "    ytarget.append(y[0][0])\n",
    "xtime = np.array(xtime)\n",
    "ytarget = np.array(ytarget)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(ytarget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Fold Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1273, 90, 36)\n",
      "(1273, 14)\n",
      "(425, 14)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import keras.utils\n",
    "from keras import utils as np_utils\n",
    "x_train,x_test,y_train,y_test = train_test_split(xtime, ytarget, test_size = 1/4, random_state = 1)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "y_train = y_train.reshape(1273,14,1)\n",
    "y_test= y_test.reshape(425,14,1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 90, 100)           54800     \n",
      "_________________________________________________________________\n",
      "lambda_6 (Lambda)            (None, 14, 100)           0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 14, 1)             101       \n",
      "=================================================================\n",
      "Total params: 54,901\n",
      "Trainable params: 54,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From //anaconda3/envs/mlenv/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 1273 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1273/1273 [==============================] - 4s 4ms/step - loss: 0.0497 - val_loss: 0.0361\n",
      "Epoch 2/200\n",
      "1273/1273 [==============================] - 3s 3ms/step - loss: 0.0385 - val_loss: 0.0366\n",
      "Epoch 3/200\n",
      "1273/1273 [==============================] - 3s 3ms/step - loss: 0.0370 - val_loss: 0.0362\n",
      "Epoch 4/200\n",
      "1273/1273 [==============================] - 3s 3ms/step - loss: 0.0364 - val_loss: 0.0361\n",
      "Epoch 5/200\n",
      "1273/1273 [==============================] - 3s 3ms/step - loss: 0.0362 - val_loss: 0.0361\n",
      "Epoch 6/200\n",
      "1273/1273 [==============================] - 3s 3ms/step - loss: 0.0360 - val_loss: 0.0361\n",
      "Epoch 7/200\n",
      "1273/1273 [==============================] - 3s 3ms/step - loss: 0.0360 - val_loss: 0.0364\n",
      "Epoch 8/200\n",
      " 896/1273 [====================>.........] - ETA: 0s - loss: 0.0355"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, dropout=.2,activation='relu', input_shape=(90, 36), return_sequences=True))\n",
    "model.add(Lambda(lambda x: x[:, -predictedDays:, :]))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='rmsprop', loss='mse')\n",
    "\n",
    "# fit model\n",
    "model.fit(x_train, y_train, validation_data=(x_test,y_test), shuffle=True, epochs=200, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "import matplotlib.pyplot as plt\n",
    "#From Sklearn documentation \n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = list(unique_labels(y_true, y_pred))\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.00887503]\n",
      "  [ 0.00156083]\n",
      "  [-0.00268951]\n",
      "  [-0.00519887]\n",
      "  [ 0.00345523]\n",
      "  [ 0.00361935]\n",
      "  [ 0.00626405]\n",
      "  [ 0.00337263]\n",
      "  [ 0.00558755]\n",
      "  [ 0.00440927]\n",
      "  [ 0.00187594]\n",
      "  [ 0.00257197]\n",
      "  [ 0.00564536]\n",
      "  [ 0.00561896]]]\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(x_test[0][np.newaxis,:,:])\n",
    "print(yhat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_test[243][np.newaxis,:,:])\n",
    "print(x_test[0].shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "print(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
