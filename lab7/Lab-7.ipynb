{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names \n",
    "Spencer Bernardo-Cheng\n",
    "Max Goldstein\n",
    "Robbie Keehan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/mlenv/lib/python3.7/site-packages/ipykernel_launcher.py:50: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "datafb = pd.read_csv(\"./FB.csv\")\n",
    "datagoogle = pd.read_csv(\"./GOOGL.csv\")\n",
    "datamsft = pd.read_csv(\"./MSFT.csv\")\n",
    "dataam = pd.read_csv(\"./AMZN (1).csv\")\n",
    "datanflx = pd.read_csv(\"./NFLX.csv\")\n",
    "\n",
    "del datafb['Date']\n",
    "del datagoogle['Date']\n",
    "del datamsft['Date']\n",
    "del datanflx['Date']\n",
    "\n",
    "\n",
    "data = pd.concat([datafb, datagoogle, datamsft,datanflx, dataam ], axis=1, sort=False)\n",
    "data = data[89:]\n",
    "del data['Change']\n",
    "del data['Gain']\n",
    "del data['Loss']\n",
    "del data['Average Gain']\n",
    "del data['Average Loss']\n",
    "del data['RS']\n",
    "del data['DM+1']\n",
    "del data['DM-1']\n",
    "del data['TR-14']\n",
    "del data['DM+1-14']\n",
    "del data['DM-1+14']\n",
    "del data['dl+1-14']\n",
    "del data['dl-1-14']\n",
    "del data['dl14diff']\n",
    "del data['dl14sum']\n",
    "del data['DX']\n",
    "del data['TR']\n",
    "ogdates = []\n",
    "for val in data['Date']:\n",
    "    ogdates.append(val)\n",
    "del data['Date']\n",
    "\n",
    "predictedDays = 14\n",
    "up = .03\n",
    "down =-.03\n",
    "## Time difference the data\n",
    "colheaders = data.columns[0:-3]\n",
    "og = []\n",
    "for val in data['Close-amzn']:\n",
    "    og.append(val)\n",
    "for header in colheaders: \n",
    "    for i in range(1, len(data)):\n",
    "        perchange =((data[header].iloc[i]) - (data[header].iloc[i - 1]))/float(data[header].iloc[i-1])\n",
    "        data.set_value(89+i,\"pc-\"+header,perchange)\n",
    "#         data[\"pc\"+header].at[90+i]= perchange\n",
    "data = data[1:]\n",
    "ydata = data['pc-Close-amzn']\n",
    "# ydata = ydata.apply(lambda x:2 if x>=up else (1 if (x< up and x > down) else 0))\n",
    "ydata = pd.DataFrame(ydata)\n",
    "ydata['newy'] = \"\"\n",
    "# created target data in format to match output of multiple timesteps of 14 days ahead\n",
    "# [0,1,2,3,4,5,6,7]\n",
    "# [1,2,3,4,5,6,7,8]\n",
    "for index, row in ydata.iterrows():\n",
    "    temp = np.array(ydata['pc-Close-amzn'][index-90:index-90+predictedDays].values)\n",
    "    ydata['newy'].at[index] = temp\n",
    "    \n",
    "# removed last 14 because their targets are not able to created\n",
    "ydata = ydata[0:-(predictedDays-1)]\n",
    "data = data[0:-(predictedDays-1)]\n",
    "\n",
    "del ydata['pc-Close-amzn']\n",
    "\n",
    "xdata =data[['RSI-14 Day', 'ADX',\n",
    "       'pc-Open-fb', 'pc-High-fb', 'pc-Low-fb', 'pc-Close-fb',\n",
    "       'pc-Adj Close-fb', 'pc-Volume-fb', 'pc-Open-googl', 'pc-High-googl',\n",
    "       'pc-Low-googl', 'pc-Close-googl', 'pc-Adj Close-googl',\n",
    "       'pc-Volume-googl', 'pc-Open-msft', 'pc-High-msft', 'pc-Low-msft',\n",
    "       'pc-Close-msft', 'pc-Adj Close-msft', 'pc-Volume-msft', 'pc-Open-nflx',\n",
    "       'pc-High-nflx', 'pc-Low-nflx', 'pc-Close-nflx', 'pc-Adj Close-nflx',\n",
    "       'pc-Volume-nflx', 'pc-Open-amzn', 'pc-High-amzn', 'pc-Low-amzn',\n",
    "       'pc-Close-amzn', 'pc-Adj Close-amzn', 'pc-Volume-amzn', 'pc-SMA-7',\n",
    "       'pc-SMA-21', 'pc-SMA-90']]\n",
    "\n",
    "\n",
    "data = data[0:-1]\n",
    "xdata = xdata[0:-1]\n",
    "ydata = ydata[0:-1]\n",
    "# data = data.T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Hot Encoding The Target Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 newy\n",
      "90  [-0.03126685348001901, -0.023788658883803833, ...\n",
      "91  [-0.023788658883803833, -0.0031430016910281716...\n",
      "92  [-0.0031430016910281716, -0.007616083827630422...\n",
      "93  [-0.007616083827630422, 0.00750945697512207, -...\n",
      "94  [0.00750945697512207, -0.0009828446509949397, ...\n",
      "                                                   newy\n",
      "90    [-0.03126685348001901, -0.023788658883803833, ...\n",
      "91    [-0.023788658883803833, -0.0031430016910281716...\n",
      "92    [-0.0031430016910281716, -0.007616083827630422...\n",
      "93    [-0.007616083827630422, 0.00750945697512207, -...\n",
      "94    [0.00750945697512207, -0.0009828446509949397, ...\n",
      "...                                                 ...\n",
      "1873  [-0.007968049902658595, 0.0035842157954330814,...\n",
      "1874  [0.0035842157954330814, -0.01399888357705284, ...\n",
      "1875  [-0.01399888357705284, 0.000849913019005562, -...\n",
      "1876  [0.000849913019005562, -0.008611641517542337, ...\n",
      "1877  [-0.008611641517542337, 0.007496472572400493, ...\n",
      "\n",
      "[1788 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "print(ydata.head())\n",
    "# ydata['newy'] = ydata['newy'].apply(lambda x: to_categorical(x,3))\n",
    "print(ydata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Min-Max Scaling the Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.35811382 0.15022488 0.40722014 ... 0.53721892 0.45230866 0.64160589]\n",
      " [0.26414926 0.12331708 0.35961381 ... 0.50635447 0.41867806 0.57327146]\n",
      " [0.25300192 0.10448737 0.40286589 ... 0.51153038 0.41312322 0.576277  ]\n",
      " ...\n",
      " [0.3029723  0.1344608  0.461637   ... 0.50352112 0.48231708 0.23750753]\n",
      " [0.31038595 0.1153046  0.38866776 ... 0.50862139 0.47320208 0.21748327]\n",
      " [0.25243424 0.13533161 0.42314792 ... 0.49730187 0.44639693 0.21806241]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(xdata.iloc[:,:].values)\n",
    "print(x_scaled)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilizing Time Series Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1698, 14)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from numpy import hstack\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Lambda, Dropout,GRU\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "n_input = 2\n",
    "series = np.array(x_scaled)\n",
    "target = np.array(ydata)\n",
    "generator = TimeseriesGenerator(series, target, length=90, batch_size=1)\n",
    "xtime = []\n",
    "ytarget =[]\n",
    "for i in range(len(generator)):\n",
    "    x, y = generator[i]\n",
    "    xtime.append(x[0])\n",
    "xtime = np.array(xtime)\n",
    "\n",
    "target = target[90:]\n",
    "newtarget = []\n",
    "for val in target:\n",
    "    newtarget.append(np.array(val[0]))\n",
    "ytarget = np.array(newtarget)\n",
    "print(ytarget.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Fold Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import keras.utils\n",
    "from keras import utils as np_utils\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 90, 100)           54400     \n",
      "_________________________________________________________________\n",
      "lambda_10 (Lambda)           (None, 14, 100)           0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 14, 1)             101       \n",
      "=================================================================\n",
      "Total params: 54,501\n",
      "Trainable params: 54,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Fold:  1\n",
      "Train on 1528 samples, validate on 170 samples\n",
      "Epoch 1/100\n",
      "1528/1528 [==============================] - 6s 4ms/step - loss: 0.0040 - val_loss: 3.6798e-04\n",
      "Epoch 2/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 9.2890e-04 - val_loss: 3.8152e-04\n",
      "Epoch 3/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 6.6518e-04 - val_loss: 3.1747e-04\n",
      "Epoch 4/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 5.6141e-04 - val_loss: 3.6399e-04\n",
      "Epoch 5/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 5.0478e-04 - val_loss: 3.0685e-04\n",
      "Epoch 6/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 4.7146e-04 - val_loss: 3.0572e-04\n",
      "Epoch 7/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 4.5441e-04 - val_loss: 3.0462e-04\n",
      "Epoch 8/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 4.3455e-04 - val_loss: 2.9641e-04\n",
      "Epoch 9/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 4.2622e-04 - val_loss: 3.0311e-04\n",
      "Epoch 10/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 4.1646e-04 - val_loss: 3.6025e-04\n",
      "Epoch 11/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 4.2265e-04 - val_loss: 2.9611e-04\n",
      "Epoch 12/100\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.9817e-04 - val_loss: 3.2860e-04\n",
      "Epoch 13/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 4.0601e-04 - val_loss: 3.0866e-04\n",
      "Epoch 14/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.9267e-04 - val_loss: 2.9356e-04\n",
      "Epoch 15/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.7870e-04 - val_loss: 2.8901e-04\n",
      "Epoch 16/100\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.7969e-04 - val_loss: 2.9266e-04\n",
      "Epoch 17/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.6917e-04 - val_loss: 2.8922e-04\n",
      "Epoch 18/100\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.7327e-04 - val_loss: 2.9716e-04\n",
      "Epoch 19/100\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.7158e-04 - val_loss: 2.9043e-04\n",
      "Epoch 20/100\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.6889e-04 - val_loss: 2.9331e-04\n",
      "Epoch 21/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.6956e-04 - val_loss: 2.8546e-04\n",
      "Epoch 22/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.6936e-04 - val_loss: 2.9782e-04\n",
      "Epoch 23/100\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.6729e-04 - val_loss: 2.8747e-04\n",
      "Epoch 24/100\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.6049e-04 - val_loss: 2.8703e-04\n",
      "Epoch 25/100\n",
      "1528/1528 [==============================] - 3s 2ms/step - loss: 3.6078e-04 - val_loss: 2.8788e-04\n",
      "Epoch 26/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.5918e-04 - val_loss: 2.8967e-04\n",
      "Epoch 27/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.6410e-04 - val_loss: 2.9252e-04\n",
      "Epoch 28/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.6602e-04 - val_loss: 2.9227e-04\n",
      "Epoch 29/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.6159e-04 - val_loss: 2.9746e-04\n",
      "Epoch 30/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.5802e-04 - val_loss: 2.8808e-04\n",
      "Epoch 31/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.5914e-04 - val_loss: 3.0801e-04\n",
      "Epoch 32/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.6566e-04 - val_loss: 2.9379e-04\n",
      "Epoch 33/100\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.5872e-04 - val_loss: 2.8953e-04\n",
      "Epoch 34/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.6036e-04 - val_loss: 2.8879e-04\n",
      "Epoch 35/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.5732e-04 - val_loss: 2.8679e-04\n",
      "Epoch 36/100\n",
      "1528/1528 [==============================] - 5s 3ms/step - loss: 3.6172e-04 - val_loss: 2.8640e-04\n",
      "Epoch 37/100\n",
      "1528/1528 [==============================] - 5s 3ms/step - loss: 3.5584e-04 - val_loss: 2.8787e-04\n",
      "Epoch 38/100\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.5475e-04 - val_loss: 3.0712e-04\n",
      "Epoch 39/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.6198e-04 - val_loss: 2.9767e-04\n",
      "Epoch 40/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.6348e-04 - val_loss: 3.0205e-04\n",
      "Epoch 41/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.5718e-04 - val_loss: 2.9673e-04\n",
      "Epoch 42/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.5670e-04 - val_loss: 2.9517e-04\n",
      "Epoch 43/100\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.5308e-04 - val_loss: 2.8874e-04\n",
      "Epoch 44/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.6489e-04 - val_loss: 2.8657e-04\n",
      "Epoch 45/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.6638e-04 - val_loss: 2.8664e-04\n",
      "Epoch 46/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.5324e-04 - val_loss: 2.9286e-04\n",
      "Epoch 47/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.5673e-04 - val_loss: 2.8914e-04\n",
      "Epoch 48/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.5131e-04 - val_loss: 2.9277e-04\n",
      "Epoch 49/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.6209e-04 - val_loss: 2.9328e-04\n",
      "Epoch 50/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.5293e-04 - val_loss: 2.8870e-04\n",
      "Epoch 51/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.5418e-04 - val_loss: 2.8766e-04\n",
      "Epoch 52/100\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.5549e-04 - val_loss: 2.9861e-04\n",
      "Epoch 53/100\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.5392e-04 - val_loss: 2.8816e-04\n",
      "Epoch 54/100\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.5452e-04 - val_loss: 2.8810e-04\n",
      "Epoch 55/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.5060e-04 - val_loss: 2.9178e-04\n",
      "Epoch 56/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.5070e-04 - val_loss: 3.1964e-04\n",
      "Epoch 57/100\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.6141e-04 - val_loss: 2.8802e-04\n",
      "Epoch 58/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.5409e-04 - val_loss: 3.0130e-04\n",
      "Epoch 59/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.4999e-04 - val_loss: 2.9358e-04\n",
      "Epoch 60/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.5711e-04 - val_loss: 2.9260e-04\n",
      "Epoch 61/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.5210e-04 - val_loss: 2.9177e-04\n",
      "Epoch 62/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.5076e-04 - val_loss: 2.8806e-04\n",
      "Epoch 63/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.5303e-04 - val_loss: 2.8833e-04\n",
      "Epoch 64/100\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.4909e-04 - val_loss: 2.9433e-04\n",
      "Epoch 65/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.4916e-04 - val_loss: 2.9348e-04\n",
      "Epoch 66/100\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.4925e-04 - val_loss: 2.8973e-04\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1528/1528 [==============================] - 5s 3ms/step - loss: 3.5031e-04 - val_loss: 2.9286e-04\n",
      "Epoch 68/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.4801e-04 - val_loss: 2.9132e-04\n",
      "Epoch 69/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.4809e-04 - val_loss: 2.9152e-04\n",
      "Epoch 70/100\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.5417e-04 - val_loss: 3.0762e-04\n",
      "Epoch 71/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.5834e-04 - val_loss: 3.0396e-04\n",
      "Epoch 72/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.5108e-04 - val_loss: 2.8670e-04\n",
      "Epoch 73/100\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.4744e-04 - val_loss: 2.8925e-04\n",
      "Epoch 74/100\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.4800e-04 - val_loss: 2.9316e-04\n",
      "Epoch 75/100\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.4811e-04 - val_loss: 2.9591e-04\n",
      "Epoch 76/100\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.5524e-04 - val_loss: 2.9870e-04\n",
      "Epoch 77/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.4879e-04 - val_loss: 2.9202e-04\n",
      "Epoch 78/100\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.4677e-04 - val_loss: 3.0720e-04\n",
      "Epoch 79/100\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.5436e-04 - val_loss: 2.9097e-04\n",
      "Epoch 80/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.4862e-04 - val_loss: 2.9342e-04\n",
      "Epoch 81/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.4878e-04 - val_loss: 2.8829e-04\n",
      "Epoch 82/100\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.4538e-04 - val_loss: 2.9124e-04\n",
      "Epoch 83/100\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.4997e-04 - val_loss: 3.2720e-04\n",
      "Epoch 84/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.5346e-04 - val_loss: 2.9687e-04\n",
      "Epoch 85/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.5313e-04 - val_loss: 2.9444e-04\n",
      "Epoch 86/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.4471e-04 - val_loss: 2.8858e-04\n",
      "Epoch 87/100\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.4550e-04 - val_loss: 2.9512e-04\n",
      "Epoch 88/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.4730e-04 - val_loss: 2.9259e-04\n",
      "Epoch 89/100\n",
      "1528/1528 [==============================] - 5s 3ms/step - loss: 3.4576e-04 - val_loss: 2.9985e-04\n",
      "Epoch 90/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.5229e-04 - val_loss: 2.9378e-04\n",
      "Epoch 91/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.4941e-04 - val_loss: 2.9095e-04\n",
      "Epoch 92/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.4334e-04 - val_loss: 2.8968e-04\n",
      "Epoch 93/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.5014e-04 - val_loss: 2.9107e-04\n",
      "Epoch 94/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.4619e-04 - val_loss: 2.9005e-04\n",
      "Epoch 95/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.4549e-04 - val_loss: 2.9084e-04\n",
      "Epoch 96/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.4333e-04 - val_loss: 3.0972e-04\n",
      "Epoch 97/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.4380e-04 - val_loss: 2.9654e-04\n",
      "Epoch 98/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.4495e-04 - val_loss: 3.0367e-04\n",
      "Epoch 99/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.4525e-04 - val_loss: 3.0981e-04\n",
      "Epoch 100/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.4583e-04 - val_loss: 2.9181e-04\n",
      "Fold:  2\n",
      "Train on 1528 samples, validate on 170 samples\n",
      "Epoch 1/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.4024e-04 - val_loss: 3.9294e-04\n",
      "Epoch 2/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.3062e-04 - val_loss: 3.9230e-04\n",
      "Epoch 3/100\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.2868e-04 - val_loss: 4.1202e-04\n",
      "Epoch 4/100\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.3013e-04 - val_loss: 3.9759e-04\n",
      "Epoch 5/100\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.3039e-04 - val_loss: 3.9225e-04\n",
      "Epoch 6/100\n",
      "1528/1528 [==============================] - 3s 2ms/step - loss: 3.3511e-04 - val_loss: 4.0375e-04\n",
      "Epoch 7/100\n",
      "1528/1528 [==============================] - 3s 2ms/step - loss: 3.3005e-04 - val_loss: 3.9671e-04\n",
      "Epoch 8/100\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.2876e-04 - val_loss: 4.0889e-04\n",
      "Epoch 9/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.2696e-04 - val_loss: 4.0515e-04\n",
      "Epoch 10/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.2929e-04 - val_loss: 4.0310e-04\n",
      "Epoch 11/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.2537e-04 - val_loss: 4.0384e-04\n",
      "Epoch 12/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.2844e-04 - val_loss: 4.1467e-04\n",
      "Epoch 13/100\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.2849e-04 - val_loss: 4.1637e-04\n",
      "Epoch 14/100\n",
      "1528/1528 [==============================] - 3s 2ms/step - loss: 3.2612e-04 - val_loss: 4.0502e-04\n",
      "Epoch 15/100\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.2416e-04 - val_loss: 4.0773e-04\n",
      "Epoch 16/100\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.2538e-04 - val_loss: 4.0753e-04\n",
      "Epoch 17/100\n",
      "1528/1528 [==============================] - 3s 2ms/step - loss: 3.2774e-04 - val_loss: 4.1190e-04\n",
      "Epoch 18/100\n",
      "1528/1528 [==============================] - 3s 2ms/step - loss: 3.2733e-04 - val_loss: 4.2993e-04\n",
      "Epoch 19/100\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.2597e-04 - val_loss: 4.1618e-04\n",
      "Epoch 20/100\n",
      "1528/1528 [==============================] - 3s 2ms/step - loss: 3.2496e-04 - val_loss: 4.2586e-04\n",
      "Epoch 21/100\n",
      "1528/1528 [==============================] - 3s 2ms/step - loss: 3.2082e-04 - val_loss: 4.1399e-04\n",
      "Epoch 22/100\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.2181e-04 - val_loss: 4.2791e-04\n",
      "Epoch 23/100\n",
      "1528/1528 [==============================] - 3s 2ms/step - loss: 3.2321e-04 - val_loss: 4.2359e-04\n",
      "Epoch 24/100\n",
      "1528/1528 [==============================] - 3s 2ms/step - loss: 3.2320e-04 - val_loss: 4.1447e-04\n",
      "Epoch 25/100\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.2587e-04 - val_loss: 4.1515e-04\n",
      "Epoch 26/100\n",
      "1528/1528 [==============================] - 3s 2ms/step - loss: 3.2089e-04 - val_loss: 4.4701e-04\n",
      "Epoch 27/100\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.2416e-04 - val_loss: 4.2853e-04\n",
      "Epoch 28/100\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.2341e-04 - val_loss: 4.2531e-04\n",
      "Epoch 29/100\n",
      "1528/1528 [==============================] - 5s 3ms/step - loss: 3.1805e-04 - val_loss: 4.2058e-04\n",
      "Epoch 30/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.1613e-04 - val_loss: 4.1494e-04\n",
      "Epoch 31/100\n",
      "1528/1528 [==============================] - 5s 3ms/step - loss: 3.2015e-04 - val_loss: 4.3682e-04\n",
      "Epoch 32/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.1961e-04 - val_loss: 4.2317e-04\n",
      "Epoch 33/100\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.2621e-04 - val_loss: 4.1603e-04\n",
      "Epoch 34/100\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.1694e-04 - val_loss: 4.1864e-04\n",
      "Epoch 35/100\n",
      "1528/1528 [==============================] - 3s 2ms/step - loss: 3.1862e-04 - val_loss: 4.2018e-04\n",
      "Epoch 36/100\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.1836e-04 - val_loss: 4.2112e-04\n",
      "Epoch 37/100\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.1739e-04 - val_loss: 4.2772e-04\n",
      "Epoch 38/100\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.1845e-04 - val_loss: 4.2518e-04\n",
      "Epoch 39/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.1615e-04 - val_loss: 4.2858e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.2091e-04 - val_loss: 4.1753e-04\n",
      "Epoch 41/100\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.1487e-04 - val_loss: 4.2151e-04\n",
      "Epoch 42/100\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.1938e-04 - val_loss: 4.3138e-04\n",
      "Epoch 43/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.1413e-04 - val_loss: 4.2184e-04\n",
      "Epoch 44/100\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.1480e-04 - val_loss: 4.2356e-04\n",
      "Epoch 45/100\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.1353e-04 - val_loss: 4.2542e-04\n",
      "Epoch 46/100\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.1723e-04 - val_loss: 4.2452e-04\n",
      "Epoch 47/100\n",
      "1528/1528 [==============================] - 3s 2ms/step - loss: 3.2018e-04 - val_loss: 4.2271e-04\n",
      "Epoch 48/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.1535e-04 - val_loss: 4.2167e-04\n",
      "Epoch 49/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.1391e-04 - val_loss: 4.6113e-04\n",
      "Epoch 50/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.1476e-04 - val_loss: 4.3076e-04\n",
      "Epoch 51/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.1435e-04 - val_loss: 4.2972e-04\n",
      "Epoch 52/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.1142e-04 - val_loss: 4.2457e-04\n",
      "Epoch 53/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.1188e-04 - val_loss: 4.4132e-04\n",
      "Epoch 54/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.1094e-04 - val_loss: 4.2238e-04\n",
      "Epoch 55/100\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.1235e-04 - val_loss: 4.2234e-04\n",
      "Epoch 56/100\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.1256e-04 - val_loss: 4.2518e-04\n",
      "Epoch 57/100\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.1151e-04 - val_loss: 4.2639e-04\n",
      "Epoch 58/100\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.1208e-04 - val_loss: 4.2558e-04\n",
      "Epoch 59/100\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.1179e-04 - val_loss: 4.1800e-04\n",
      "Epoch 60/100\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.0947e-04 - val_loss: 4.2961e-04\n",
      "Epoch 61/100\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.1455e-04 - val_loss: 4.2473e-04\n",
      "Epoch 62/100\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.0924e-04 - val_loss: 4.2901e-04\n",
      "Epoch 63/100\n",
      "1528/1528 [==============================] - 3s 2ms/step - loss: 3.1140e-04 - val_loss: 4.3794e-04\n",
      "Epoch 64/100\n",
      "1528/1528 [==============================] - 3s 2ms/step - loss: 3.0820e-04 - val_loss: 4.2761e-04\n",
      "Epoch 65/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.0740e-04 - val_loss: 4.2631e-04\n",
      "Epoch 66/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.0789e-04 - val_loss: 4.2904e-04\n",
      "Epoch 67/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.0970e-04 - val_loss: 4.3186e-04\n",
      "Epoch 68/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.1122e-04 - val_loss: 4.3114e-04\n",
      "Epoch 69/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.0608e-04 - val_loss: 4.2604e-04\n",
      "Epoch 70/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.0810e-04 - val_loss: 4.2090e-04\n",
      "Epoch 71/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.0489e-04 - val_loss: 4.2209e-04\n",
      "Epoch 72/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.0888e-04 - val_loss: 4.2618e-04\n",
      "Epoch 73/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.0513e-04 - val_loss: 4.2405e-04\n",
      "Epoch 74/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.0495e-04 - val_loss: 4.4244e-04\n",
      "Epoch 75/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.0598e-04 - val_loss: 4.3159e-04\n",
      "Epoch 76/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.0430e-04 - val_loss: 4.1953e-04\n",
      "Epoch 77/100\n",
      "1528/1528 [==============================] - 4s 3ms/step - loss: 3.0502e-04 - val_loss: 4.3310e-04\n",
      "Epoch 78/100\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.0612e-04 - val_loss: 4.2612e-04\n",
      "Epoch 79/100\n",
      "1344/1528 [=========================>....] - ETA: 0s - loss: 3.0240e-04"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-d09254dff458>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0my_test\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m170\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mhistoriesLSTM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mk\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m#     score = model.score(x_train[test_index], y_train[test_index])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/envs/mlenv/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m//anaconda3/envs/mlenv/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/envs/mlenv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/envs/mlenv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/envs/mlenv/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(100,dropout=.2,activation='relu', input_shape=(90, 35), return_sequences=True))\n",
    "model.add(Lambda(lambda x: x[:, -predictedDays:, :]))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=False, random_state=None)\n",
    "# fit model\n",
    "historiesLSTM = []\n",
    "# scores = []\n",
    "\n",
    "k = 1\n",
    "# for train_index, test_index in kfold.split(xtime, ytarget):\n",
    "for train_index, test_index in kfold.split(xtime, ytarget):\n",
    "    print(\"Fold: \", k)\n",
    "    x_train, x_test = xtime[train_index], xtime[test_index]\n",
    "    y_train, y_test = ytarget[train_index], ytarget[test_index]\n",
    "    y_train = y_train.reshape(1528,14,1)\n",
    "    y_test= y_test.reshape(170,14,1)\n",
    "    \n",
    "    historiesLSTM.append(model.fit(x_train, y_train, validation_data=(x_test,y_test), epochs=100, verbose=1))\n",
    "    k += 1\n",
    "#     score = model.score(x_train[test_index], y_train[test_index])\n",
    "#     scores.append(score)\n",
    "#     print('Fold: %s, Acc: %.3f' % (k+1, score))\n",
    "    \n",
    "# print('\\nCV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))\n",
    "\n",
    "# history = model.fit(x_train, y_train, validation_data=(x_test,y_test), epochs=50, verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Validation & Training Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.ylabel('MSE Training Loss')\n",
    "plt.xlabel('epochs')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_1 (GRU)                  (None, 90, 100)           40800     \n",
      "_________________________________________________________________\n",
      "lambda_3 (Lambda)            (None, 14, 100)           0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 14, 1)             101       \n",
      "=================================================================\n",
      "Total params: 40,901\n",
      "Trainable params: 40,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Fold:  1\n",
      "Train on 1528 samples, validate on 170 samples\n",
      "Epoch 1/5\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 0.0027 - val_loss: 3.5762e-04\n",
      "Epoch 2/5\n",
      "1528/1528 [==============================] - 3s 2ms/step - loss: 7.8702e-04 - val_loss: 3.1788e-04\n",
      "Epoch 3/5\n",
      "1528/1528 [==============================] - 3s 2ms/step - loss: 6.0836e-04 - val_loss: 3.1200e-04\n",
      "Epoch 4/5\n",
      "1528/1528 [==============================] - 3s 2ms/step - loss: 5.0339e-04 - val_loss: 2.8755e-04\n",
      "Epoch 5/5\n",
      "1528/1528 [==============================] - 3s 2ms/step - loss: 4.6083e-04 - val_loss: 3.1502e-04\n",
      "Fold:  2\n",
      "Train on 1528 samples, validate on 170 samples\n",
      "Epoch 1/5\n",
      "1528/1528 [==============================] - 3s 2ms/step - loss: 4.1000e-04 - val_loss: 4.0803e-04\n",
      "Epoch 2/5\n",
      "1528/1528 [==============================] - 3s 2ms/step - loss: 3.8386e-04 - val_loss: 4.1477e-04\n",
      "Epoch 3/5\n",
      "1528/1528 [==============================] - 3s 2ms/step - loss: 3.7199e-04 - val_loss: 4.2492e-04\n",
      "Epoch 4/5\n",
      "1376/1528 [==========================>...] - ETA: 0s - loss: 3.7559e-04"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-f015dea2bfcc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0my_test\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m170\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mhistoriesGRU\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mk\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM, Lambda, Dropout,GRU\n",
    "\n",
    "gru = Sequential()\n",
    "gru.add(GRU(100,dropout=.2,activation='relu', input_shape=(90, 35), return_sequences=True))\n",
    "gru.add(Lambda(lambda x: x[:, -predictedDays:, :]))\n",
    "gru.add(Dense(1))\n",
    "\n",
    "gru.summary()\n",
    "gru.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=False, random_state=None)\n",
    "# fit model\n",
    "historiesGRU = []\n",
    "# scores = []\n",
    "\n",
    "k = 1\n",
    "# for train_index, test_index in kfold.split(xtime, ytarget):\n",
    "for train_index, test_index in kfold.split(xtime, ytarget):\n",
    "    print(\"Fold: \", k)\n",
    "    x_train, x_test = xtime[train_index], xtime[test_index]\n",
    "    y_train, y_test = ytarget[train_index], ytarget[test_index]\n",
    "    y_train = y_train.reshape(1528,14,1)\n",
    "    y_test= y_test.reshape(170,14,1)\n",
    "    \n",
    "    historiesGRU.append(gru.fit(x_train, y_train, validation_data=(x_test,y_test), epochs=5, verbose=1))\n",
    "    k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.ylabel('MSE Training Loss')\n",
    "plt.xlabel('epochs')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacked RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_2 (GRU)                  (None, 90, 100)           40800     \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 90, 100)           60300     \n",
      "_________________________________________________________________\n",
      "lambda_4 (Lambda)            (None, 14, 100)           0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 14, 1)             101       \n",
      "=================================================================\n",
      "Total params: 101,201\n",
      "Trainable params: 101,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Fold:  1\n",
      "Train on 1528 samples, validate on 170 samples\n",
      "Epoch 1/5\n",
      "1528/1528 [==============================] - 7s 5ms/step - loss: 0.0020 - val_loss: 3.3158e-04\n",
      "Epoch 2/5\n",
      "1528/1528 [==============================] - 5s 3ms/step - loss: 5.4071e-04 - val_loss: 3.5705e-04\n",
      "Epoch 3/5\n",
      "1528/1528 [==============================] - 5s 3ms/step - loss: 4.5558e-04 - val_loss: 2.9638e-04\n",
      "Epoch 4/5\n",
      "1528/1528 [==============================] - 5s 3ms/step - loss: 4.1530e-04 - val_loss: 2.7836e-04\n",
      "Epoch 5/5\n",
      "1528/1528 [==============================] - 5s 3ms/step - loss: 3.9871e-04 - val_loss: 2.7967e-04\n",
      "Fold:  2\n",
      "Train on 1528 samples, validate on 170 samples\n",
      "Epoch 1/5\n",
      "1528/1528 [==============================] - 5s 3ms/step - loss: 3.6755e-04 - val_loss: 4.1026e-04\n",
      "Epoch 2/5\n",
      "1528/1528 [==============================] - 5s 4ms/step - loss: 3.5798e-04 - val_loss: 4.0883e-04\n",
      "Epoch 3/5\n",
      "1528/1528 [==============================] - 6s 4ms/step - loss: 3.5417e-04 - val_loss: 4.1133e-04\n",
      "Epoch 4/5\n",
      "1528/1528 [==============================] - 6s 4ms/step - loss: 3.4957e-04 - val_loss: 4.1005e-04\n",
      "Epoch 5/5\n",
      "1528/1528 [==============================] - 6s 4ms/step - loss: 3.4896e-04 - val_loss: 4.1031e-04\n",
      "Fold:  3\n",
      "Train on 1528 samples, validate on 170 samples\n",
      "Epoch 1/5\n",
      "1088/1528 [====================>.........] - ETA: 1s - loss: 3.3400e-04"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-7a96615ea902>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0my_test\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m170\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mhistoriesStacked\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelstacked\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mk\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "modelstacked = Sequential()\n",
    "modelstacked.add(GRU(100,dropout=.2,recurrent_dropout=.2,activation='relu', input_shape=(90, 35), return_sequences=True))\n",
    "modelstacked.add(GRU(100,dropout=.4,activation='relu', return_sequences=True))\n",
    "\n",
    "modelstacked.add(Lambda(lambda x: x[:, -predictedDays:, :]))\n",
    "\n",
    "modelstacked.add(Dense(1))\n",
    "\n",
    "modelstacked.summary()\n",
    "modelstacked.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=False, random_state=None)\n",
    "# fit model\n",
    "historiesStacked = []\n",
    "# scores = []\n",
    "\n",
    "k = 1\n",
    "# for train_index, test_index in kfold.split(xtime, ytarget):\n",
    "for train_index, test_index in kfold.split(xtime, ytarget):\n",
    "    print(\"Fold: \", k)\n",
    "    x_train, x_test = xtime[train_index], xtime[test_index]\n",
    "    y_train, y_test = ytarget[train_index], ytarget[test_index]\n",
    "    y_train = y_train.reshape(1528,14,1)\n",
    "    y_test= y_test.reshape(170,14,1)\n",
    "    \n",
    "    historiesStacked.append(modelstacked.fit(x_train, y_train, validation_data=(x_test,y_test), epochs=5, verbose=1))\n",
    "    k += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(historystacked.history['loss'])\n",
    "plt.ylabel('MSE Training Loss')\n",
    "plt.xlabel('epochs')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(historystacked.history['val_loss'])\n",
    "plt.xlabel('epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backtracing GRU Prediction vs Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = 1274\n",
    "timeplus = 231\n",
    "yhat = gru.predict(x_test[timeplus][np.newaxis,:,:])\n",
    "print(yhat[0].ravel())\n",
    "print(y_test[0].ravel())\n",
    "print(og[base-90 + timeplus:base+14+timeplus])\n",
    "# print(yhat[0] - y_test[0])\n",
    "backtesting = og[base-90+timeplus:base+timeplus]\n",
    "print(len(backtesting))\n",
    "yhatBack=og[base-1+timeplus]\n",
    "ytestBack = og[base-1+timeplus]\n",
    "ytest_backtesting=og[base-90+timeplus:base+timeplus]\n",
    "\n",
    "for i,val in enumerate(yhat[0].ravel()):\n",
    "#     print(yhatBack)\n",
    "    yhatBack = yhatBack * (1+val)\n",
    "    \n",
    "    backtesting.append(yhatBack)\n",
    "\n",
    "for i,val in enumerate(y_test[0].ravel()):\n",
    "#     print(ytestBack)\n",
    "    ytestBack = ytestBack * (1+val)\n",
    "    \n",
    "    ytest_backtesting.append(ytestBack)\n",
    "xbacktest= [x for x in range(0,104)]\n",
    "plt.plot(xbacktest,backtesting,'b-')\n",
    "plt.plot(xbacktest,ytest_backtesting,'r-')\n",
    "plt.title(\"{} - {}\".format(ogdates[base-90+timeplus],ogdates[base+14+timeplus]))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backtracing for LSTM and Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = 1274\n",
    "timeplus = 0\n",
    "yhat = model.predict(x_test[timeplus][np.newaxis,:,:])\n",
    "print(yhat[0].ravel())\n",
    "print(y_test[0].ravel())\n",
    "print(og[base-90 + timeplus:base+14+timeplus])\n",
    "# print(yhat[0] - y_test[0])\n",
    "backtesting = og[base-90+timeplus:base+timeplus]\n",
    "yhatBack=og[base-1+timeplus]\n",
    "ytestBack = og[base-1+timeplus]\n",
    "ytest_backtesting=og[base-90+timeplus:base+timeplus]\n",
    "\n",
    "for i,val in enumerate(yhat[0].ravel()):\n",
    "#     print(yhatBack)\n",
    "    yhatBack = yhatBack * (1+val)\n",
    "    \n",
    "    backtesting.append(yhatBack)\n",
    "\n",
    "for i,val in enumerate(y_test[0].ravel()):\n",
    "#     print(ytestBack)\n",
    "    ytestBack = ytestBack * (1+val)\n",
    "    \n",
    "    ytest_backtesting.append(ytestBack)\n",
    "xbacktest= [x for x in range(0,104)]\n",
    "plt.plot(xbacktest,backtesting,'b-')\n",
    "plt.plot(xbacktest,ytest_backtesting,'r-')\n",
    "plt.title(\"{} - {}\".format(ogdates[base-90+timeplus],ogdates[base+14+timeplus]))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backtracing for Stacked GRU and Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = 1274\n",
    "timeplus = 0\n",
    "yhat = modelstacked.predict(x_test[timeplus][np.newaxis,:,:])\n",
    "print(yhat[0].ravel())\n",
    "print(y_test[0].ravel())\n",
    "print(og[base-90 + timeplus:base+14+timeplus])\n",
    "# print(yhat[0] - y_test[0])\n",
    "backtesting = og[base-90+timeplus:base+timeplus]\n",
    "yhatBack=og[base-1+timeplus]\n",
    "ytestBack = og[base-1+timeplus]\n",
    "ytest_backtesting=og[base-90+timeplus:base+timeplus]\n",
    "\n",
    "for i,val in enumerate(yhat[0].ravel()):\n",
    "#     print(yhatBack)\n",
    "    yhatBack = yhatBack * (1+val)\n",
    "    \n",
    "    backtesting.append(yhatBack)\n",
    "\n",
    "for i,val in enumerate(y_test[0].ravel()):\n",
    "#     print(ytestBack)\n",
    "    ytestBack = ytestBack * (1+val)\n",
    "    \n",
    "    ytest_backtesting.append(ytestBack)\n",
    "xbacktest= [x for x in range(0,104)]\n",
    "plt.plot(xbacktest,backtesting,'b-')\n",
    "plt.plot(xbacktest,ytest_backtesting,'r-')\n",
    "plt.title(\"{} - {}\".format(ogdates[base-90+timeplus],ogdates[base+14+timeplus]))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Credit - Trading Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making fake data\n",
    "#I found out I can use emojis with this new mac touchbar😁👏👌\n",
    "starting_price = 258.670013\n",
    "price = 258.670013\n",
    "price1 = price * -0.25 + price\n",
    "price2 =  price1 * 0.4 + price1\n",
    "price3 =  price2 * 0.25 + price2\n",
    "prices = [price,price1,price2,price3]\n",
    "daysPredicted = 3\n",
    "testArr = [[0.2,0.3,-0.2],[0.3,-0.2,0.4],[-0.2,0.4,0.25],[0.4,0.25,-0.1],[0.25,-0.1,-0.2]]\n",
    "print(prices)\n",
    "#start with owning 1 share\n",
    "bought = True\n",
    "#owns 1 share\n",
    "value = 1\n",
    "#index of time from where we are predicting \n",
    "price_index = 0\n",
    "for i in range(daysPredicted-1,len(testArr)):\n",
    "    val_for_next_day = 0\n",
    "    # i2 is for traversing back the amount of days predicted\n",
    "    i2 = i\n",
    "    # i3 is for moving to the right position in the specific day to get the next days prediction \n",
    "    i3 = 0\n",
    "    # it starts at 1, goes to 2, and then goes to 3\n",
    "    # This will predict the next day \n",
    "    # [[*,*,3],[*,2,*],[1,*,*]]\n",
    "    while(i2 > i-daysPredicted):\n",
    "        val_for_next_day += testArr[i2][i3] * 1/daysPredicted\n",
    "        i2-=1\n",
    "        i3+=1\n",
    "    # if the value for the next day is positive and we haven't bought then we buy\n",
    "    if(val_for_next_day > 0 and not bought):\n",
    "        bought = True\n",
    "        print('bought at',price)\n",
    "        value = value / price\n",
    "    # if the value for the next day is negative and we own shares then we sell\n",
    "    if(val_for_next_day < 0 and bought):\n",
    "        bought = False\n",
    "        print('sold at at',price)\n",
    "        value = price * value\n",
    "    # set the value to the next closing price\n",
    "    price_index +=1\n",
    "    price = prices[price_index]\n",
    "\n",
    "if(bought):\n",
    "    value = price * value\n",
    "\n",
    "#this was made assuming you bought 1 share\n",
    "print(' Staring Value:',starting_price,'\\n',\n",
    "      'Value of trading alorithm:', value, '\\n',\n",
    "      'Value of buying and holding:',(1*price3))\n",
    "#technically we can own fractional parts of share with this algo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
