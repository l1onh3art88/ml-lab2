{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names \n",
    "Spencer Bernardo-Cheng\n",
    "Max Goldstein\n",
    "Robbie Keehan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:50: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "datafb = pd.read_csv(\"./FB.csv\")\n",
    "datagoogle = pd.read_csv(\"./GOOGL.csv\")\n",
    "datamsft = pd.read_csv(\"./MSFT.csv\")\n",
    "dataam = pd.read_csv(\"./AMZN (1).csv\")\n",
    "datanflx = pd.read_csv(\"./NFLX.csv\")\n",
    "\n",
    "del datafb['Date']\n",
    "del datagoogle['Date']\n",
    "del datamsft['Date']\n",
    "del datanflx['Date']\n",
    "\n",
    "\n",
    "data = pd.concat([datafb, datagoogle, datamsft,datanflx, dataam ], axis=1, sort=False)\n",
    "data = data[89:]\n",
    "del data['Change']\n",
    "del data['Gain']\n",
    "del data['Loss']\n",
    "del data['Average Gain']\n",
    "del data['Average Loss']\n",
    "del data['RS']\n",
    "del data['DM+1']\n",
    "del data['DM-1']\n",
    "del data['TR-14']\n",
    "del data['DM+1-14']\n",
    "del data['DM-1+14']\n",
    "del data['dl+1-14']\n",
    "del data['dl-1-14']\n",
    "del data['dl14diff']\n",
    "del data['dl14sum']\n",
    "del data['DX']\n",
    "del data['TR']\n",
    "ogdates = []\n",
    "for val in data['Date']:\n",
    "    ogdates.append(val)\n",
    "del data['Date']\n",
    "\n",
    "predictedDays = 14\n",
    "up = .03\n",
    "down =-.03\n",
    "## Time difference the data\n",
    "colheaders = data.columns[0:-3]\n",
    "og = []\n",
    "for val in data['Close-amzn']:\n",
    "    og.append(val)\n",
    "for header in colheaders: \n",
    "    for i in range(1, len(data)):\n",
    "        perchange =((data[header].iloc[i]) - (data[header].iloc[i - 1]))/float(data[header].iloc[i-1])\n",
    "        data.set_value(89+i,\"pc-\"+header,perchange)\n",
    "#         data[\"pc\"+header].at[90+i]= perchange\n",
    "data = data[1:]\n",
    "ydata = data['pc-Close-amzn']\n",
    "# ydata = ydata.apply(lambda x:2 if x>=up else (1 if (x< up and x > down) else 0))\n",
    "ydata = pd.DataFrame(ydata)\n",
    "ydata['newy'] = \"\"\n",
    "# created target data in format to match output of multiple timesteps of 14 days ahead\n",
    "# [0,1,2,3,4,5,6,7]\n",
    "# [1,2,3,4,5,6,7,8]\n",
    "for index, row in ydata.iterrows():\n",
    "    temp = np.array(ydata['pc-Close-amzn'][index-90:index-90+predictedDays].values)\n",
    "    ydata['newy'].at[index] = temp\n",
    "    \n",
    "# removed last 14 because their targets are not able to created\n",
    "ydata = ydata[0:-(predictedDays-1)]\n",
    "data = data[0:-(predictedDays-1)]\n",
    "\n",
    "del ydata['pc-Close-amzn']\n",
    "\n",
    "xdata =data[['RSI-14 Day', 'ADX',\n",
    "       'pc-Open-fb', 'pc-High-fb', 'pc-Low-fb', 'pc-Close-fb',\n",
    "       'pc-Adj Close-fb', 'pc-Volume-fb', 'pc-Open-googl', 'pc-High-googl',\n",
    "       'pc-Low-googl', 'pc-Close-googl', 'pc-Adj Close-googl',\n",
    "       'pc-Volume-googl', 'pc-Open-msft', 'pc-High-msft', 'pc-Low-msft',\n",
    "       'pc-Close-msft', 'pc-Adj Close-msft', 'pc-Volume-msft', 'pc-Open-nflx',\n",
    "       'pc-High-nflx', 'pc-Low-nflx', 'pc-Close-nflx', 'pc-Adj Close-nflx',\n",
    "       'pc-Volume-nflx', 'pc-Open-amzn', 'pc-High-amzn', 'pc-Low-amzn',\n",
    "       'pc-Close-amzn', 'pc-Adj Close-amzn', 'pc-Volume-amzn', 'pc-SMA-7',\n",
    "       'pc-SMA-21', 'pc-SMA-90']]\n",
    "\n",
    "\n",
    "data = data[0:-1]\n",
    "xdata = xdata[0:-1]\n",
    "ydata = ydata[0:-1]\n",
    "# data = data.T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Hot Encoding The Target Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 newy\n",
      "90  [-0.03126685348001901, -0.023788658883803833, ...\n",
      "91  [-0.023788658883803833, -0.0031430016910281716...\n",
      "92  [-0.0031430016910281716, -0.007616083827630422...\n",
      "93  [-0.007616083827630422, 0.00750945697512207, -...\n",
      "94  [0.00750945697512207, -0.0009828446509949397, ...\n",
      "                                                   newy\n",
      "90    [-0.03126685348001901, -0.023788658883803833, ...\n",
      "91    [-0.023788658883803833, -0.0031430016910281716...\n",
      "92    [-0.0031430016910281716, -0.007616083827630422...\n",
      "93    [-0.007616083827630422, 0.00750945697512207, -...\n",
      "94    [0.00750945697512207, -0.0009828446509949397, ...\n",
      "95    [-0.0009828446509949397, 0.014552771053924872,...\n",
      "96    [0.014552771053924872, -0.010667093404438537, ...\n",
      "97    [-0.010667093404438537, -0.01980806976169732, ...\n",
      "98    [-0.01980806976169732, -0.0259166708333332, 0....\n",
      "99    [-0.0259166708333332, 0.0022670844480582584, -...\n",
      "100   [0.0022670844480582584, -0.02483885898885134, ...\n",
      "101   [-0.02483885898885134, -0.024377464563493604, ...\n",
      "102   [-0.024377464563493604, 0.06872423801116298, -...\n",
      "103   [0.06872423801116298, -0.022456371254693148, -...\n",
      "104   [-0.022456371254693148, -0.0032204044966310467...\n",
      "105   [-0.0032204044966310467, 0.0012061643887573861...\n",
      "106   [0.0012061643887573861, 0.00821789870250328, 0...\n",
      "107   [0.00821789870250328, 0.013783962669876134, -0...\n",
      "108   [0.013783962669876134, -0.02315204599387141, -...\n",
      "109   [-0.02315204599387141, -0.020296440750637253, ...\n",
      "110   [-0.020296440750637253, -0.004574479756116656,...\n",
      "111   [-0.004574479756116656, 0.0007070080925013335,...\n",
      "112   [0.0007070080925013335, 0.0005740495404512304,...\n",
      "113   [0.0005740495404512304, -0.01610771802009565, ...\n",
      "114   [-0.01610771802009565, -0.010540439702271073, ...\n",
      "115   [-0.010540439702271073, 0.020988168060158584, ...\n",
      "116   [0.020988168060158584, 0.019890827507717892, 0...\n",
      "117   [0.019890827507717892, 0.01771795688465606, 0....\n",
      "118   [0.01771795688465606, 0.01817948506364738, 0.0...\n",
      "119   [0.01817948506364738, 0.0077721548030588805, 0...\n",
      "...                                                 ...\n",
      "1848  [-0.00401804380396445, -0.015669562099450956, ...\n",
      "1849  [-0.015669562099450956, 0.00966278702755876, -...\n",
      "1850  [0.00966278702755876, -0.0010046399863216477, ...\n",
      "1851  [-0.0010046399863216477, 0.006778064904269904,...\n",
      "1852  [0.006778064904269904, 0.0026040520840578353, ...\n",
      "1853  [0.0026040520840578353, 0.017823897328144298, ...\n",
      "1854  [0.017823897328144298, 0.005686410942506925, 0...\n",
      "1855  [0.005686410942506925, 0.005654189304036682, -...\n",
      "1856  [0.005654189304036682, -0.01676660456918789, 0...\n",
      "1857  [-0.01676660456918789, 0.01601699213081569, -0...\n",
      "1858  [0.01601699213081569, -0.011161169327038837, -...\n",
      "1859  [-0.011161169327038837, -0.0020161270637766935...\n",
      "1860  [-0.0020161270637766935, 0.010560833821551345,...\n",
      "1861  [0.010560833821551345, -0.010922220983645254, ...\n",
      "1862  [-0.010922220983645254, 0.00894210647263868, -...\n",
      "1863  [0.00894210647263868, -0.00808629625891734, 0....\n",
      "1864  [-0.00808629625891734, 0.009803103960561204, -...\n",
      "1865  [0.009803103960561204, -0.0018707723182195038,...\n",
      "1866  [-0.0018707723182195038, 0.008318928054414768,...\n",
      "1867  [0.008318928054414768, 0.007379590405146552, -...\n",
      "1868  [0.007379590405146552, -0.0016346973637251696,...\n",
      "1869  [-0.0016346973637251696, -0.003296835300118591...\n",
      "1870  [-0.003296835300118591, -0.004215500267678974,...\n",
      "1871  [-0.004215500267678974, -0.0012973638650994866...\n",
      "1872  [-0.0012973638650994866, -0.007968049902658595...\n",
      "1873  [-0.007968049902658595, 0.0035842157954330814,...\n",
      "1874  [0.0035842157954330814, -0.01399888357705284, ...\n",
      "1875  [-0.01399888357705284, 0.000849913019005562, -...\n",
      "1876  [0.000849913019005562, -0.008611641517542337, ...\n",
      "1877  [-0.008611641517542337, 0.007496472572400493, ...\n",
      "\n",
      "[1788 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "print(ydata.head())\n",
    "# ydata['newy'] = ydata['newy'].apply(lambda x: to_categorical(x,3))\n",
    "print(ydata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Min-Max Scaling the Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.35811382 0.15022488 0.40722014 ... 0.53721892 0.45230866 0.64160589]\n",
      " [0.26414926 0.12331708 0.35961381 ... 0.50635447 0.41867806 0.57327146]\n",
      " [0.25300192 0.10448737 0.40286589 ... 0.51153038 0.41312322 0.576277  ]\n",
      " ...\n",
      " [0.3029723  0.1344608  0.461637   ... 0.50352112 0.48231708 0.23750753]\n",
      " [0.31038595 0.1153046  0.38866776 ... 0.50862139 0.47320208 0.21748327]\n",
      " [0.25243424 0.13533161 0.42314792 ... 0.49730187 0.44639693 0.21806241]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(xdata.iloc[:,:].values)\n",
    "print(x_scaled)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilizing Time Series Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1698, 14)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from numpy import hstack\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Lambda, Dropout,GRU\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "n_input = 2\n",
    "series = np.array(x_scaled)\n",
    "target = np.array(ydata)\n",
    "generator = TimeseriesGenerator(series, target, length=90, batch_size=1)\n",
    "xtime = []\n",
    "ytarget =[]\n",
    "for i in range(len(generator)):\n",
    "    x, y = generator[i]\n",
    "    xtime.append(x[0])\n",
    "xtime = np.array(xtime)\n",
    "\n",
    "target = target[90:]\n",
    "newtarget = []\n",
    "for val in target:\n",
    "    newtarget.append(np.array(val[0]))\n",
    "ytarget = np.array(newtarget)\n",
    "print(ytarget.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Fold Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import keras.utils\n",
    "from keras import utils as np_utils\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 90, 100)           54400     \n",
      "_________________________________________________________________\n",
      "lambda_2 (Lambda)            (None, 14, 100)           0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 14, 1)             101       \n",
      "=================================================================\n",
      "Total params: 54,501\n",
      "Trainable params: 54,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Fold:  1\n",
      "Train on 1528 samples, validate on 170 samples\n",
      "Epoch 1/5\n",
      "1528/1528 [==============================] - 5s 3ms/step - loss: 0.0051 - val_loss: 5.7786e-04\n",
      "Epoch 2/5\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 9.2584e-04 - val_loss: 4.0997e-04\n",
      "Epoch 3/5\n",
      "1528/1528 [==============================] - 3s 2ms/step - loss: 6.2785e-04 - val_loss: 3.1192e-04\n",
      "Epoch 4/5\n",
      "1528/1528 [==============================] - 3s 2ms/step - loss: 5.1324e-04 - val_loss: 2.9041e-04\n",
      "Epoch 5/5\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 4.7575e-04 - val_loss: 3.2338e-04\n",
      "Fold:  2\n",
      "Train on 1528 samples, validate on 170 samples\n",
      "Epoch 1/5\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 4.4456e-04 - val_loss: 4.1656e-04\n",
      "Epoch 2/5\n",
      "1528/1528 [==============================] - 3s 2ms/step - loss: 4.2553e-04 - val_loss: 4.2049e-04\n",
      "Epoch 3/5\n",
      "1528/1528 [==============================] - 3s 2ms/step - loss: 3.9635e-04 - val_loss: 4.2217e-04\n",
      "Epoch 4/5\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.9928e-04 - val_loss: 4.2737e-04\n",
      "Epoch 5/5\n",
      "1528/1528 [==============================] - 3s 2ms/step - loss: 3.8451e-04 - val_loss: 4.2268e-04\n",
      "Fold:  3\n",
      "Train on 1528 samples, validate on 170 samples\n",
      "Epoch 1/5\n",
      "1528/1528 [==============================] - 3s 2ms/step - loss: 3.7601e-04 - val_loss: 4.3483e-04\n",
      "Epoch 2/5\n",
      "1528/1528 [==============================] - 3s 2ms/step - loss: 3.6755e-04 - val_loss: 4.2988e-04\n",
      "Epoch 3/5\n",
      "1528/1528 [==============================] - 3s 2ms/step - loss: 3.6737e-04 - val_loss: 4.3249e-04\n",
      "Epoch 4/5\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 3.6097e-04 - val_loss: 4.3166e-04\n",
      "Epoch 5/5\n",
      "1528/1528 [==============================] - 3s 2ms/step - loss: 3.5702e-04 - val_loss: 4.2732e-04\n",
      "Fold:  4\n",
      "Train on 1528 samples, validate on 170 samples\n",
      "Epoch 1/5\n",
      "1280/1528 [========================>.....] - ETA: 0s - loss: 3.5253e-04"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-0ef32da449c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0my_test\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m170\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mhistoriesLSTM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mk\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m#     score = model.score(x_train[test_index], y_train[test_index])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(100,dropout=.2,activation='relu', input_shape=(90, 35), return_sequences=True))\n",
    "model.add(Lambda(lambda x: x[:, -predictedDays:, :]))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=False, random_state=None)\n",
    "# fit model\n",
    "historiesLSTM = []\n",
    "# scores = []\n",
    "\n",
    "k = 1\n",
    "# for train_index, test_index in kfold.split(xtime, ytarget):\n",
    "for train_index, test_index in kfold.split(xtime, ytarget):\n",
    "    print(\"Fold: \", k)\n",
    "    x_train, x_test = xtime[train_index], xtime[test_index]\n",
    "    y_train, y_test = ytarget[train_index], ytarget[test_index]\n",
    "    y_train = y_train.reshape(1528,14,1)\n",
    "    y_test= y_test.reshape(170,14,1)\n",
    "    \n",
    "    historiesLSTM.append(model.fit(x_train, y_train, validation_data=(x_test,y_test), epochs=5, verbose=1))\n",
    "    k += 1\n",
    "#     score = model.score(x_train[test_index], y_train[test_index])\n",
    "#     scores.append(score)\n",
    "#     print('Fold: %s, Acc: %.3f' % (k+1, score))\n",
    "    \n",
    "# print('\\nCV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))\n",
    "\n",
    "# history = model.fit(x_train, y_train, validation_data=(x_test,y_test), epochs=50, verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Validation & Training Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.ylabel('MSE Training Loss')\n",
    "plt.xlabel('epochs')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_1 (GRU)                  (None, 90, 100)           40800     \n",
      "_________________________________________________________________\n",
      "lambda_3 (Lambda)            (None, 14, 100)           0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 14, 1)             101       \n",
      "=================================================================\n",
      "Total params: 40,901\n",
      "Trainable params: 40,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Fold:  1\n",
      "Train on 1528 samples, validate on 170 samples\n",
      "Epoch 1/5\n",
      "1528/1528 [==============================] - 4s 2ms/step - loss: 0.0027 - val_loss: 3.5762e-04\n",
      "Epoch 2/5\n",
      "1528/1528 [==============================] - 3s 2ms/step - loss: 7.8702e-04 - val_loss: 3.1788e-04\n",
      "Epoch 3/5\n",
      "1528/1528 [==============================] - 3s 2ms/step - loss: 6.0836e-04 - val_loss: 3.1200e-04\n",
      "Epoch 4/5\n",
      "1528/1528 [==============================] - 3s 2ms/step - loss: 5.0339e-04 - val_loss: 2.8755e-04\n",
      "Epoch 5/5\n",
      "1528/1528 [==============================] - 3s 2ms/step - loss: 4.6083e-04 - val_loss: 3.1502e-04\n",
      "Fold:  2\n",
      "Train on 1528 samples, validate on 170 samples\n",
      "Epoch 1/5\n",
      "1528/1528 [==============================] - 3s 2ms/step - loss: 4.1000e-04 - val_loss: 4.0803e-04\n",
      "Epoch 2/5\n",
      "1528/1528 [==============================] - 3s 2ms/step - loss: 3.8386e-04 - val_loss: 4.1477e-04\n",
      "Epoch 3/5\n",
      "1528/1528 [==============================] - 3s 2ms/step - loss: 3.7199e-04 - val_loss: 4.2492e-04\n",
      "Epoch 4/5\n",
      "1376/1528 [==========================>...] - ETA: 0s - loss: 3.7559e-04"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-f015dea2bfcc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0my_test\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m170\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mhistoriesGRU\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mk\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM, Lambda, Dropout,GRU\n",
    "\n",
    "gru = Sequential()\n",
    "gru.add(GRU(100,dropout=.2,activation='relu', input_shape=(90, 35), return_sequences=True))\n",
    "gru.add(Lambda(lambda x: x[:, -predictedDays:, :]))\n",
    "gru.add(Dense(1))\n",
    "\n",
    "gru.summary()\n",
    "gru.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=False, random_state=None)\n",
    "# fit model\n",
    "historiesGRU = []\n",
    "# scores = []\n",
    "\n",
    "k = 1\n",
    "# for train_index, test_index in kfold.split(xtime, ytarget):\n",
    "for train_index, test_index in kfold.split(xtime, ytarget):\n",
    "    print(\"Fold: \", k)\n",
    "    x_train, x_test = xtime[train_index], xtime[test_index]\n",
    "    y_train, y_test = ytarget[train_index], ytarget[test_index]\n",
    "    y_train = y_train.reshape(1528,14,1)\n",
    "    y_test= y_test.reshape(170,14,1)\n",
    "    \n",
    "    historiesGRU.append(gru.fit(x_train, y_train, validation_data=(x_test,y_test), epochs=5, verbose=1))\n",
    "    k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.ylabel('MSE Training Loss')\n",
    "plt.xlabel('epochs')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacked RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_2 (GRU)                  (None, 90, 100)           40800     \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 90, 100)           60300     \n",
      "_________________________________________________________________\n",
      "lambda_4 (Lambda)            (None, 14, 100)           0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 14, 1)             101       \n",
      "=================================================================\n",
      "Total params: 101,201\n",
      "Trainable params: 101,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Fold:  1\n",
      "Train on 1528 samples, validate on 170 samples\n",
      "Epoch 1/5\n",
      "1528/1528 [==============================] - 7s 5ms/step - loss: 0.0020 - val_loss: 3.3158e-04\n",
      "Epoch 2/5\n",
      "1528/1528 [==============================] - 5s 3ms/step - loss: 5.4071e-04 - val_loss: 3.5705e-04\n",
      "Epoch 3/5\n",
      "1528/1528 [==============================] - 5s 3ms/step - loss: 4.5558e-04 - val_loss: 2.9638e-04\n",
      "Epoch 4/5\n",
      "1528/1528 [==============================] - 5s 3ms/step - loss: 4.1530e-04 - val_loss: 2.7836e-04\n",
      "Epoch 5/5\n",
      "1528/1528 [==============================] - 5s 3ms/step - loss: 3.9871e-04 - val_loss: 2.7967e-04\n",
      "Fold:  2\n",
      "Train on 1528 samples, validate on 170 samples\n",
      "Epoch 1/5\n",
      "1528/1528 [==============================] - 5s 3ms/step - loss: 3.6755e-04 - val_loss: 4.1026e-04\n",
      "Epoch 2/5\n",
      "1528/1528 [==============================] - 5s 4ms/step - loss: 3.5798e-04 - val_loss: 4.0883e-04\n",
      "Epoch 3/5\n",
      "1528/1528 [==============================] - 6s 4ms/step - loss: 3.5417e-04 - val_loss: 4.1133e-04\n",
      "Epoch 4/5\n",
      "1528/1528 [==============================] - 6s 4ms/step - loss: 3.4957e-04 - val_loss: 4.1005e-04\n",
      "Epoch 5/5\n",
      "1528/1528 [==============================] - 6s 4ms/step - loss: 3.4896e-04 - val_loss: 4.1031e-04\n",
      "Fold:  3\n",
      "Train on 1528 samples, validate on 170 samples\n",
      "Epoch 1/5\n",
      "1088/1528 [====================>.........] - ETA: 1s - loss: 3.3400e-04"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-7a96615ea902>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0my_test\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m170\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mhistoriesStacked\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelstacked\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mk\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "modelstacked = Sequential()\n",
    "modelstacked.add(GRU(100,dropout=.2,recurrent_dropout=.2,activation='relu', input_shape=(90, 35), return_sequences=True))\n",
    "modelstacked.add(GRU(100,dropout=.4,activation='relu', return_sequences=True))\n",
    "\n",
    "modelstacked.add(Lambda(lambda x: x[:, -predictedDays:, :]))\n",
    "\n",
    "modelstacked.add(Dense(1))\n",
    "\n",
    "modelstacked.summary()\n",
    "modelstacked.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=False, random_state=None)\n",
    "# fit model\n",
    "historiesStacked = []\n",
    "# scores = []\n",
    "\n",
    "k = 1\n",
    "# for train_index, test_index in kfold.split(xtime, ytarget):\n",
    "for train_index, test_index in kfold.split(xtime, ytarget):\n",
    "    print(\"Fold: \", k)\n",
    "    x_train, x_test = xtime[train_index], xtime[test_index]\n",
    "    y_train, y_test = ytarget[train_index], ytarget[test_index]\n",
    "    y_train = y_train.reshape(1528,14,1)\n",
    "    y_test= y_test.reshape(170,14,1)\n",
    "    \n",
    "    historiesStacked.append(modelstacked.fit(x_train, y_train, validation_data=(x_test,y_test), epochs=5, verbose=1))\n",
    "    k += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(historystacked.history['loss'])\n",
    "plt.ylabel('MSE Training Loss')\n",
    "plt.xlabel('epochs')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(historystacked.history['val_loss'])\n",
    "plt.xlabel('epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backtracing GRU Prediction vs Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = 1274\n",
    "timeplus = 231\n",
    "yhat = gru.predict(x_test[timeplus][np.newaxis,:,:])\n",
    "print(yhat[0].ravel())\n",
    "print(y_test[0].ravel())\n",
    "print(og[base-90 + timeplus:base+14+timeplus])\n",
    "# print(yhat[0] - y_test[0])\n",
    "backtesting = og[base-90+timeplus:base+timeplus]\n",
    "print(len(backtesting))\n",
    "yhatBack=og[base-1+timeplus]\n",
    "ytestBack = og[base-1+timeplus]\n",
    "ytest_backtesting=og[base-90+timeplus:base+timeplus]\n",
    "\n",
    "for i,val in enumerate(yhat[0].ravel()):\n",
    "#     print(yhatBack)\n",
    "    yhatBack = yhatBack * (1+val)\n",
    "    \n",
    "    backtesting.append(yhatBack)\n",
    "\n",
    "for i,val in enumerate(y_test[0].ravel()):\n",
    "#     print(ytestBack)\n",
    "    ytestBack = ytestBack * (1+val)\n",
    "    \n",
    "    ytest_backtesting.append(ytestBack)\n",
    "xbacktest= [x for x in range(0,104)]\n",
    "plt.plot(xbacktest,backtesting,'b-')\n",
    "plt.plot(xbacktest,ytest_backtesting,'r-')\n",
    "plt.title(\"{} - {}\".format(ogdates[base-90+timeplus],ogdates[base+14+timeplus]))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backtracing for LSTM and Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = 1274\n",
    "timeplus = 0\n",
    "yhat = model.predict(x_test[timeplus][np.newaxis,:,:])\n",
    "print(yhat[0].ravel())\n",
    "print(y_test[0].ravel())\n",
    "print(og[base-90 + timeplus:base+14+timeplus])\n",
    "# print(yhat[0] - y_test[0])\n",
    "backtesting = og[base-90+timeplus:base+timeplus]\n",
    "yhatBack=og[base-1+timeplus]\n",
    "ytestBack = og[base-1+timeplus]\n",
    "ytest_backtesting=og[base-90+timeplus:base+timeplus]\n",
    "\n",
    "for i,val in enumerate(yhat[0].ravel()):\n",
    "#     print(yhatBack)\n",
    "    yhatBack = yhatBack * (1+val)\n",
    "    \n",
    "    backtesting.append(yhatBack)\n",
    "\n",
    "for i,val in enumerate(y_test[0].ravel()):\n",
    "#     print(ytestBack)\n",
    "    ytestBack = ytestBack * (1+val)\n",
    "    \n",
    "    ytest_backtesting.append(ytestBack)\n",
    "xbacktest= [x for x in range(0,104)]\n",
    "plt.plot(xbacktest,backtesting,'b-')\n",
    "plt.plot(xbacktest,ytest_backtesting,'r-')\n",
    "plt.title(\"{} - {}\".format(ogdates[base-90+timeplus],ogdates[base+14+timeplus]))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backtracing for Stacked GRU and Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = 1274\n",
    "timeplus = 0\n",
    "yhat = modelstacked.predict(x_test[timeplus][np.newaxis,:,:])\n",
    "print(yhat[0].ravel())\n",
    "print(y_test[0].ravel())\n",
    "print(og[base-90 + timeplus:base+14+timeplus])\n",
    "# print(yhat[0] - y_test[0])\n",
    "backtesting = og[base-90+timeplus:base+timeplus]\n",
    "yhatBack=og[base-1+timeplus]\n",
    "ytestBack = og[base-1+timeplus]\n",
    "ytest_backtesting=og[base-90+timeplus:base+timeplus]\n",
    "\n",
    "for i,val in enumerate(yhat[0].ravel()):\n",
    "#     print(yhatBack)\n",
    "    yhatBack = yhatBack * (1+val)\n",
    "    \n",
    "    backtesting.append(yhatBack)\n",
    "\n",
    "for i,val in enumerate(y_test[0].ravel()):\n",
    "#     print(ytestBack)\n",
    "    ytestBack = ytestBack * (1+val)\n",
    "    \n",
    "    ytest_backtesting.append(ytestBack)\n",
    "xbacktest= [x for x in range(0,104)]\n",
    "plt.plot(xbacktest,backtesting,'b-')\n",
    "plt.plot(xbacktest,ytest_backtesting,'r-')\n",
    "plt.title(\"{} - {}\".format(ogdates[base-90+timeplus],ogdates[base+14+timeplus]))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_test[243][np.newaxis,:,:])\n",
    "print(x_test[0].shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "print(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
