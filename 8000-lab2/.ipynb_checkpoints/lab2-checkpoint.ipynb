{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2\n",
    "    -Robbie Keehan\n",
    "    -Spencer Cheng\n",
    "    -Max Goldstein"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make VGG use unpooling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is taken directly from the example. Not sure if I did strided stuff right "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D, Input\n",
    "from keras.utils.data_utils import get_file\n",
    "import keras.backend as K\n",
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "MEAN_PIXEL = np.array([103.939, 116.779, 123.68])\n",
    "\n",
    "WEIGHTS_PATH = get_file('vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                        WEIGHTS_PATH_NO_TOP,\n",
    "                        cache_subdir='models',\n",
    "                        file_hash='253f8cb515780f3b799900260a226db6')\n",
    "\n",
    "def vgg_layers(inputs, target_layer):\n",
    "    # Block 1\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(inputs)\n",
    "    if target_layer == 1:\n",
    "        return x\n",
    "    #added this to make stirdes to the convolution layer\n",
    "    #honestly not sure if this is what he wanted\n",
    "    #repeated it for each ending conolution in VGG\n",
    "    x = Conv2D(64, (3, 3), activation='relu', strides=(2, 2), padding='same', name='block1_conv2')(x)\n",
    "    # x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "    if target_layer == 2:\n",
    "        return x\n",
    "    x = Conv2D(128, (3, 3), activation='relu', strides=(2, 2), padding='same', name='block2_conv2')(x)\n",
    "    # x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "    if target_layer == 3:\n",
    "        return x\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', strides=(2, 2), padding='same', name='block3_conv4')(x)\n",
    "    # x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "    if target_layer == 4:\n",
    "        return x\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', strides=(2, 2), padding='same', name='block4_conv4')(x)\n",
    "    # x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def load_weights(model):\n",
    "    f = h5py.File(WEIGHTS_PATH)\n",
    "    layer_names = [name for name in f.attrs['layer_names']]\n",
    "\n",
    "    for layer in model.layers:\n",
    "        b_name = layer.name.encode()\n",
    "        if b_name in layer_names:\n",
    "            g = f[b_name]\n",
    "            weights = [g[name] for name in g.attrs['weight_names']]\n",
    "            layer.set_weights(weights)\n",
    "            layer.trainable = False\n",
    "\n",
    "    f.close()\n",
    "\n",
    "\n",
    "def VGG19(input_tensor=None, input_shape=None, target_layer=1):\n",
    "    \"\"\"\n",
    "    VGG19, up to the target layer (1 for relu1_1, 2 for relu2_1, etc.)\n",
    "    \"\"\"\n",
    "    if input_tensor is None:\n",
    "        inputs = Input(shape=input_shape)\n",
    "    else:\n",
    "        inputs = Input(tensor=input_tensor, shape=input_shape)\n",
    "    model = Model(inputs, vgg_layers(inputs, target_layer), name='vgg19')\n",
    "    load_weights(model)\n",
    "    return model\n",
    "\n",
    "\n",
    "def preprocess_input(x):\n",
    "    # Convert 'RGB' -> 'BGR'\n",
    "    if type(x) is np.ndarray:\n",
    "        x = x[..., ::-1]\n",
    "    else:\n",
    "        x = tf.reverse(x, [-1])\n",
    "\n",
    "    return x - MEAN_PIXEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a decoder\n",
    "was trying to use yihao's decoder that he posted here: https://smu.instructure.com/courses/68239/discussion_topics/196477\n",
    "Honestly not sure about it because it wont load \n",
    "https://github.com/jackwangshanghai/CS8321HW2_Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot parse file b'./Model/Block5_Model/saved_model.pb': Error parsing message.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDecodeError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/anaconda/envs/mlenv/lib/python3.6/site-packages/tensorflow_core/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m     67\u001b[0m       \u001b[0mfile_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFileIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_pb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m       \u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParseFromString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDecodeError\u001b[0m: Error parsing message",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b32e5f35c65c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mO1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_by_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mAE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVGG19AE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./Model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0mImage_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m384\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m384\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m#Make it 4D Tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-b32e5f35c65c>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, files_path)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVGG19AE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;31m#Load Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mModelBlock5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/Block5_Model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;31m#Get Each SubModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelBlock5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/mlenv/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m     \u001b[0mloader_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/mlenv/lib/python3.6/site-packages/tensorflow_core/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDecodeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot parse file %s: %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpath_to_pb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mfile_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_pbtxt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot parse file b'./Model/Block5_Model/saved_model.pb': Error parsing message."
     ]
    }
   ],
   "source": [
    "class VGG19AE(tf.keras.Model):\n",
    "    def __init__(self, files_path):\n",
    "        super(VGG19AE, self).__init__()\n",
    "        #Load Model\n",
    "        ModelBlock5 = tf.keras.models.load_model(files_path + '/Block5_Model', compile = False)\n",
    "        #Get Each SubModel\n",
    "        self.E5 = ModelBlock5.layers[0]\n",
    "        self.D5 = ModelBlock5.layers[1]\n",
    "        self.O5 = ModelBlock5.layers[2]\n",
    "        ModelBlock4 = tf.keras.models.load_model(files_path + '/Block4_Model', compile = False)\n",
    "        self.E4 = ModelBlock4.layers[0]\n",
    "        self.D4 = ModelBlock4.layers[1]\n",
    "        self.O4 = ModelBlock4.layers[2]\n",
    "        ModelBlock3 = tf.keras.models.load_model(files_path + '/Block3_Model', compile = False)\n",
    "        self.E3 = ModelBlock3.layers[0]\n",
    "        self.D3 = ModelBlock3.layers[1]\n",
    "        self.O3 = ModelBlock3.layers[2]\n",
    "        ModelBlock2 = tf.keras.models.load_model(files_path + '/Block2_Model', compile = False)\n",
    "        self.E2 = ModelBlock2.layers[0]\n",
    "        self.D2 = ModelBlock2.layers[1]\n",
    "        self.O2 = ModelBlock2.layers[2]\n",
    "        ModelBlock1 = tf.keras.models.load_model(files_path + '/Block1_Model', compile = False)\n",
    "        self.E1 = ModelBlock1.layers[0]\n",
    "        self.O1 = ModelBlock1.layers[1]\n",
    "\n",
    "    def call(self, Image, training  = False):\n",
    "        # Input should be 4D Tensor\n",
    "        x = self.E5(Image)\n",
    "        x = self.D5(x)\n",
    "        x = self.O5(x)\n",
    "        # Block 1 Donot have decoder because it don't contain Pooling and there are only one Conv layer.\n",
    "        x = self.E1(x)\n",
    "        x = self.O1(x)\n",
    "        return tf.clip_by_value(tf.squeeze(x), 0, 1)\n",
    "AE = VGG19AE('./Model')\n",
    "Image_sample = tf.zeros([384,384,3])\n",
    "#Make it 4D Tensor\n",
    "Image_sample_input = tf.expand_dims(Image_sample, 0)\n",
    "Out_image = AE(Image_sample_input)\n",
    "print(Out_image)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show image reconstruction from the decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add whitening and coloring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mlenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
